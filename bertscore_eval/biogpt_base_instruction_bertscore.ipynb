{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c2d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from bert_score import score as bert_score\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a8239d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BioGptForCausalLM(\n",
       "  (biogpt): BioGptModel(\n",
       "    (embed_tokens): BioGptScaledWordEmbedding(42384, 1024, padding_idx=1)\n",
       "    (embed_positions): BioGptLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x BioGptDecoderLayer(\n",
       "        (self_attn): BioGptAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_projection): Linear(in_features=1024, out_features=42384, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"./biogpt_instruction_finetuned\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "THRESHOLD = 0.85\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab919425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\")[\"train\"]  # evaluation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f80ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [23:47<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_answers = []\n",
    "reference_answers = []\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    question = sample[\"question\"]\n",
    "    context_passages = sample[\"context\"][\"contexts\"]\n",
    "    context = \" \".join(context_passages)\n",
    "    prompt = f\"Question: {question}\\nContext: {context}\\nAnswer:\"\n",
    "\n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_answer = generated_text.replace(prompt, \"\").strip()\n",
    "    generated_answers.append(generated_answer)\n",
    "    reference_answers.append(sample[\"long_answer\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a0c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8763b21ef0c64052b1a811be709ed88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3842f31dd6e4e6b84c0ea07d4e63a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 29.85 seconds, 33.50 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = bert_score(generated_answers, reference_answers, lang=\"en\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16ee207",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_matches = (F1 >= THRESHOLD).numpy()\n",
    "accuracy = np.mean(soft_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c2582bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BioGPT Text Answer Evaluation (on 1000 samples):\n",
      "1. Soft Accuracy (BERTScore F1 ≥ 85%): 0.0680\n",
      "2. BERTScore Precision: 0.7888\n",
      "3. BERTScore Recall:    0.8748\n",
      "4. BERTScore F1:        0.8295\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBioGPT Text Answer Evaluation (on {len(dataset)} samples):\")\n",
    "print(f\"1. Soft Accuracy (BERTScore F1 ≥ {int(THRESHOLD*100)}%): {accuracy:.4f}\")\n",
    "print(f\"2. BERTScore Precision: {P.mean():.4f}\")\n",
    "print(f\"3. BERTScore Recall:    {R.mean():.4f}\")\n",
    "print(f\"4. BERTScore F1:        {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef2c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 932 wrong predictions to biogpt_wrong_answers0.85.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "questions = dataset[\"question\"]\n",
    "contexts = [\" \".join(ctx[\"contexts\"]) for ctx in dataset[\"context\"]]\n",
    "pubids = dataset[\"pubid\"]\n",
    "\n",
    "threshold = 0.85\n",
    "f1_scores = F1.numpy()\n",
    "wrong_indices = [i for i, score in enumerate(f1_scores) if score < threshold]\n",
    "\n",
    "wrong_df = pd.DataFrame({\n",
    "    \"PubMed ID\": [pubids[i] for i in wrong_indices],\n",
    "    \"Question\": [questions[i] for i in wrong_indices],\n",
    "    \"Context\": [contexts[i] for i in wrong_indices],\n",
    "    \"Generated Answer\": [generated_answers[i] for i in wrong_indices],\n",
    "    \"Gold Answer\": [reference_answers[i] for i in wrong_indices],\n",
    "    \"BERTScore F1\": [f1_scores[i] for i in wrong_indices]\n",
    "})\n",
    "\n",
    "wrong_df.to_csv(\"biogpt_instruction_0.85_wrong_answers.csv\", index=False)\n",
    "print(f\"Saved {len(wrong_df)} wrong predictions to biogpt_wrong_answers0.85.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biogpt_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
